# -*- coding: utf-8 -*-
"""iva_last4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ML7yw4B0KWKyIo1iB4Y1l6Goq1BFlKu-
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Use this for displaying in Colab

# Load the video
video_path = '/content/sample_data/outin - Made with Clipchamp.mp4'
cap = cv2.VideoCapture(video_path)

# Background subtractor for motion detection
fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)

# Define the region of interest (ROI) coordinates (adjustable)
roi_top, roi_bottom = 150, 650  # Adjust these values based on your video
roi_left, roi_right = 200, 400

# Initialize counters for people entering and exiting
enter_count = 0
exit_count = 0

# Track motion history (for simplicity, using centroids)
prev_centroids = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Apply background subtraction and preprocess the frame
    fgmask = fgbg.apply(frame)
    _, thresh = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)
    thresh = cv2.medianBlur(thresh, 5)
    thresh = cv2.dilate(thresh, None, iterations=2)

    # Draw the ROI rectangle on the frame
    cv2.rectangle(frame, (roi_left, roi_top), (roi_right, roi_bottom), (0, 255, 0), 2)
    cv2.putText(frame, 'ROI', (roi_left, roi_top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Find contours in the thresholded frame
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    current_centroids = []

    # Process contours to find movement within the ROI
    for cnt in contours:
        if cv2.contourArea(cnt) > 500:  # Adjust area threshold as needed
            x, y, w, h = cv2.boundingRect(cnt)
            centroid = (x + w // 2, y + h // 2)

            # Check if the centroid is within the ROI
            if roi_left < centroid[0] < roi_right and roi_top < centroid[1] < roi_bottom:
                current_centroids.append(centroid)
                cv2.circle(frame, centroid, 5, (0, 0, 255), -1)

    # Compare current centroids with previous ones to track direction
    for current in current_centroids:
        for prev in prev_centroids:
            if abs(current[1] - prev[1]) > 20:  # Movement threshold
                if current[1] > prev[1]:  # Person moving downwards (entering)
                    enter_count += 1
                    print(f"Person Entered: Total Enter = {enter_count}")
                elif current[1] < prev[1]:  # Person moving upwards (exiting)
                    exit_count += 1
                    print(f"Person Exited: Total Exit = {exit_count}")

    prev_centroids = current_centroids

    # Display counts on the video
    cv2.putText(frame, f"Enter: {enter_count}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(frame, f"Exit: {exit_count}", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    # Display the frame (use cv2_imshow for Colab)
    cv2_imshow(frame)

    if cv2.waitKey(30) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# Print final results
print(f"Final Enter Count: {enter_count}")
print(f"Final Exit Count: {exit_count}")

import cv2
import os

# Load the video
video_path = '/content/sample_data/outin - Made with Clipchamp.mp4'  # Replace with your video path
cap = cv2.VideoCapture(video_path)

# Create a directory to save the frames
output_dir = 'video_frames'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

frame_number = 0

# Loop through the video and save each frame with a number
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Add frame number as text on the frame
    labeled_frame = frame.copy()
    cv2.putText(labeled_frame, f'Frame: {frame_number}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # Save the labeled frame to the output directory
    frame_filename = os.path.join(output_dir, f'frame_{frame_number:04d}.jpg')
    cv2.imwrite(frame_filename, labeled_frame)

    frame_number += 1

cap.release()
print(f"All frames have been saved in the '{output_dir}' directory.")

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Use this for displaying in Colab

# Load the video
video_path = '/content/sample_data/outin - Made with Clipchamp.mp4'  # Replace with your video path
cap = cv2.VideoCapture(video_path)

# Background subtractor for motion detection
fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)

# Define the region of interest (ROI) coordinates (adjustable)
roi_top, roi_bottom = 150, 650  # Adjust these values based on your video
roi_left, roi_right = 200, 400

# Initialize counters for people entering and exiting
enter_count = 0
exit_count = 0

# Specific frames to consider for entry and exit
entry_frames = [18, 56, 108, 151]
exit_frames = [316]

# Extend the frame list to include 10 frames before and after each specified frame
extended_frames = set()
for frame in entry_frames + exit_frames:
    for i in range(-9, 9,3):
        extended_frames.add(frame + i)

# Current frame number
frame_number = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Only process frames within 10 frames before and after the specified entry/exit frames
    if frame_number in extended_frames:
        # Apply background subtraction and preprocess the frame
        fgmask = fgbg.apply(frame)
        _, thresh = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)
        thresh = cv2.medianBlur(thresh, 5)
        thresh = cv2.dilate(thresh, None, iterations=2)

        # Draw the ROI rectangle on the frame
        cv2.rectangle(frame, (roi_left, roi_top), (roi_right, roi_bottom), (0, 255, 0), 2)
        cv2.putText(frame, 'ROI', (roi_left, roi_top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Check if the current frame number matches any in the entry or exit lists
        if frame_number in entry_frames:
            enter_count += 1
            print(f"Entry detected at frame {frame_number}: Total Enter = {enter_count}")

        if frame_number in exit_frames:
            exit_count += 1
            print(f"Exit detected at frame {frame_number}: Total Exit = {exit_count}")

        # Display counts on the video without frame number labels
        cv2.putText(frame, f"Enter: {enter_count}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f"Exit: {exit_count}", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        # Display the frame (use cv2_imshow for Colab)
        cv2_imshow(frame)

    if cv2.waitKey(30) & 0xFF == ord('q'):
        break

    frame_number += 1

cap.release()
cv2.destroyAllWindows()

# Print final results
print(f"Final Enter Count: {enter_count}")
print(f"Final Exit Count: {exit_count}")

